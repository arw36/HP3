---
title: "HP3: Zoogeographical Cross-Validation"
output:
  html_document:
    toc: TRUE
    code_download: TRUE
    keep_md: FALSE
---

```{r setup, include=FALSE, cache=FALSE}
library(mgcv)
library(raster)
library(dplyr)
library(stringi)
library(parallel)
library(purrr)
library(ggplot2)
library(viridis)
library(knitr)
library(svglite)
library(sp)
library(readr)
library(rgdal)
library(stringr)
library(classInt)
library(maptools)
library(tibble)
library(mgcv)
library(tidyr)
library(DT)
P <- rprojroot::find_rstudio_root_file
source(P("R/model_reduction.R"))
source(P("R/fit_gam.R"))
source(P("R/relative_contributions.R"))
source(P("R/cross_validation.R"))
source(P("R/cv_gam_by.R"))
set.seed(0)
opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE, autodep=TRUE)
```


```{r db-loading, cache = TRUE}
db <- readRDS(P("intermediates", "postprocessed_database.rds"))
hosts <- db[["hosts"]]
host_names <- read_csv(P("data/hosts.csv")) %>%
  dplyr::select(hHostNameFinal, Common_names_Eng)

```
# Zoogeographic Cross-Validation

In addition to randomly-selected k-fold cross-validation, we evaluated the robustness of our models via non-random geographic cross-validation: we systematically removed all observations from a zoogeographical region, re-fit the model using all observations from outside the region, then performed a non-parametric permutation test comparing the predicted values to the observed values for that region.

In order to meaningfully organize geographic areas, we utilized mammalian zoogeographic regions from [*Holt et al (2013)*](http://dx.doi.org/10.1126/science.1228282) which are defined by distributions of and phylogenetic relationships between species. Using QGIS, a mammal-specific zoogeographical shapefile provided by [Holt's group](http://macroecology.ku.dk/resources/wallace) at the University of Copenhagen was intersected (using QGIS Vector > Geoprocessing Tools > Intersect) with a shapefile of IUCN's host ranges. Areas of these intersections were then calculated using an equal-area projection, and each host was assigned to only the region which contained the greatest proportion of its range. Results of the non-parametric permutation test are shown below; non-significant results indicate that model predictions are unbiased.

```{r map-setup, cache = TRUE, message=FALSE}
zregions <- shapefile(P("shapefiles", "mam", "mam.shp"), verbose = FALSE)
#Intersected with IUCN habitat shapefile in QGIS
zoog_mammals <- shapefile(P("shapefiles", "host_zg_area", "host_zg_area.shp"), verbose = FALSE)
zoog_mammals_data <- as_tibble(zoog_mammals@data)

#Paring down the dataset
zgm_reduced <- zoog_mammals_data %>%
  select(BINOMIAL, mam_upgma_, garea2)
#Assigning only largest areas
zgm <- zgm_reduced %>%
  group_by(BINOMIAL) %>%
  mutate(area = max(garea2)) %>%
  filter(garea2 == area) %>%
  arrange(BINOMIAL)
zgm <- unique(zgm)

region_names <- readRDS(P("data/region_names.rds"))

sp_rng_lookup <- left_join(zgm, region_names, by = c("mam_upgma_" = "fold")) %>%
  select(name, BINOMIAL) %>%
  group_by(name) %>%
  nest()



```

## Zoonoses GAM - All Associations

```{r all-zoo, cache=TRUE}
data_set = hosts %>% 
  filter(hMarOTerr == "Terrestrial",
         hWildDomFAO == "wild",
         !is.na(PdHoSa.cbCst_order))

#  Create dummy variables for orders to use as random effects
dummys = as.data.frame(with(data_set, model.matrix(~hOrder))[,-1])
data_set = cbind(data_set, dummys)

###### ALL ZOONOSES
allz_gam = readRDS(P("intermediates", "all_zoonoses_models.rds"))$model[[1]]

joined_dat <- left_join(data_set, zgm, by=c("hHostNameFinal"="BINOMIAL"))
joined_dat <- filter_down(allz_gam, joined_dat, "mam_upgma_")

results<-cv_gam_by_zg(allz_gam, joined_dat,unique(joined_dat$mam_upgma_))

allz_dat <- joined_dat

##############

zregions@data <- left_join(zregions@data, results, by=c("mam_upgma_"="fold"))

data("wrld_simpl")
small_world <- subset(wrld_simpl, wrld_simpl@data$NAME != "Antarctica")
plot(small_world)

zregions %>%
  subset(zregions@data$p_value < 0.05 & zregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="red")

zregions %>%
  subset(zregions@data$p_value < 0.05 & zregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="pink")

zregions %>%
  subset(zregions@data$p_value >= 0.05 & zregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="darkgreen")

zregions %>%
  subset(zregions@data$p_value >= 0.05 & zregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="lightgreen")

title("All Zoonoses: 31 Regions")
```

Dark green indicates unbiased regions, while dark red indicates regions with evidence of biased predictions. Light green and light red represent the same distinction, but these regions contain very few (less than ten) assigned species; blank areas were not assigned any hosts. 

```{r all-zoo-tables, results = "asis"}
results<-left_join(results, region_names, by = "fold")

results %>% arrange(fold) %>%
  filter(n_validate > 10, p_value < 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Zoonoses)` = mean_diff) %>%
  kable(caption = "Biased Predictions Regions (n > 10)", digits = 4)

results %>% arrange(fold) %>%
  filter(n_validate > 10, p_value >= 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Zoonoses)` = mean_diff) %>%
  kable(caption = "Unbiased Prediction Regions (n > 10)", digits = 4)

```


## All Viruses GAM - All Associations

```{r all-viruses, cache = TRUE}
###### ALL VIRUSES
allv_gam = readRDS(P("intermediates", "all_viruses_models.rds"))$model[[1]]
vregions <- shapefile(P("shapefiles", "mam", "mam.shp"), verbose = FALSE)

temp <- left_join(data_set, zgm, by=c("hHostNameFinal"="BINOMIAL"))
temp <- filter_down(allv_gam, temp, "mam_upgma_")



allv_dat <- temp

vresults<-cv_gam_by_zg(allv_gam, temp,unique(temp$mam_upgma_))

vregions@data <- left_join(vregions@data, vresults, by=c("mam_upgma_"="fold"))

plot(small_world)

vregions %>%
  subset(vregions@data$p_value < 0.05 & vregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="red")

vregions %>%
  subset(vregions@data$p_value < 0.05 & vregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="pink")

vregions %>%
  subset(vregions@data$p_value >= 0.05 & vregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="darkgreen")

vregions %>%
  subset(vregions@data$p_value >= 0.05 & vregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="lightgreen")

title("All Viruses: 31 Regions")
```

Dark green indicates unbiased regions, while dark red indicates regions with evidence of biased predictions. Light green and light red represent the same distinction, but these regions contain very few (less than ten) assigned species; blank areas were not assigned any hosts. 

```{r all-virus-tables, results = "asis"}
vresults<-left_join(vresults, region_names, by = "fold")

vresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value < 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Viruses)` = mean_diff) %>%
  kable(caption = "Biased Predictions Regions (n > 10)", digits = 4)

vresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value >= 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Viruses)` = mean_diff) %>%
  kable(caption = "Unbiased Prediction Regions (n > 10)", digits = 4)

```



## Zoonoses GAM - Strict Associations

```{r strict-zoo, cache = TRUE}
strictz_gam <- readRDS(P("intermediates", "all_zoonoses_strict_models.rds"))$model[[1]]

szregions <- shapefile(P("shapefiles", "mam", "mam.shp"), verbose = FALSE)

temp <- left_join(data_set, zgm, by=c("hHostNameFinal"="BINOMIAL"))
temp <- filter_down(strictz_gam, temp, "mam_upgma_")

strictz_dat <- temp

#########

szresults<-cv_gam_by_zg(strictz_gam, temp,unique(temp$mam_upgma_))

szregions@data <- left_join(szregions@data, szresults, by=c("mam_upgma_"="fold"))

plot(small_world)

szregions %>%
  subset(szregions@data$p_value < 0.05 & szregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="red")

szregions %>%
  subset(szregions@data$p_value < 0.05 & szregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="pink")

szregions %>%
  subset(szregions@data$p_value >= 0.05 & szregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="darkgreen")

szregions %>%
  subset(szregions@data$p_value >= 0.05 & szregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="lightgreen")

title("Strict Zoonoses: 31 Regions")
```

Dark green indicates unbiased regions, while dark red indicates regions with evidence of biased predictions. Light green and light red represent the same distinction, but these regions contain very few (less than ten) assigned 
species; blank areas were not assigned any hosts.  

```{r sz-tables, results = "asis"}
szresults<-left_join(szresults, region_names, by = "fold")

szresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value < 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Zoonoses)` = mean_diff) %>%
  kable(caption = "Biased Predictions Regions (n > 10)", digits = 4)
```

```{r sz-tables2}
szresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value >= 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Zoonoses)` = mean_diff) %>%
  kable(caption = "Unbiased Prediction Regions (n > 10)", digits = 4)

```


## All Viruses GAM - Strict Associations

```{r strict-viruses, cache = TRUE}
strictv_gam <- readRDS(P("intermediates", "all_viruses_strict_models.rds"))$model[[1]]

svregions <- shapefile(P("shapefiles", "mam", "mam.shp"), verbose = FALSE)

temp <- left_join(data_set, zgm, by=c("hHostNameFinal"="BINOMIAL"))
temp <- filter_down(strictv_gam, temp, "mam_upgma_")

strictv_dat <- temp

svresults<-cv_gam_by_zg(strictv_gam, temp,unique(temp$mam_upgma_))

svregions@data <- left_join(svregions@data, svresults, by=c("mam_upgma_"="fold"))

plot(small_world)

svregions %>%
  subset(svregions@data$p_value < 0.05 & svregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="red")

svregions %>%
  subset(svregions@data$p_value < 0.05 & svregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="pink")

svregions %>%
  subset(svregions@data$p_value >= 0.05 & svregions@data$n_validate > 10) %>%
  plot(.,add=TRUE, col="darkgreen")

svregions %>%
  subset(svregions@data$p_value >= 0.05 & svregions@data$n_validate < 10) %>%
  plot(.,add=TRUE, col="lightgreen")

title("Strict Viruses: 31 Regions")
```

Dark green indicates unbiased regions, while dark red indicates regions with evidence of biased predictions. Light green and light red represent the same distinction, but these regions contain very few (less than ten) assigned species; blank areas were not assigned any hosts. 

```{r strict-zoo-tables, results = "asis"}
svresults<-left_join(svresults, region_names, by = "fold")

svresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value < 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Viruses)` = mean_diff) %>%
  kable(caption = "Biased Predictions Regions (n > 10)", digits = 4)

svresults %>% arrange(fold) %>%
  filter(n_validate > 10, p_value >= 0.05) %>%
  select(name, n_fit, n_validate, p_value, mean_diff) %>%
  rename(Region = name, `Observations Fit` = n_fit, `Observations Held Out` = n_validate, 
         `P-value` = p_value, `Mean Prediction Difference (Number of Viruses)` = mean_diff) %>%
  kable(caption = "Unbiased Prediction Regions (n > 10)", digits = 4)
```

##Cross-validation Interpretation
The reviewer articulated concerns about our models' ability to make out-of-sample predictions, arguing that cross-validation based on random folds does not adequately address this issue. Accordingly, we performed a non-random cross-validation using zoogeography to determine folds. The results of this procedure show that for the *All Zoonoses*, *All Viruses*, and *Strict Viruses* models, most regions do not show evidence of bias (that is, a systematic over- or under-prediction of model outcome greater than what one would expect due to chance). For each of these three models, only 4-5 substantial (n > 10) folds show evidence of bias, while 10-11 substantial folds do not. The mean size of these prediction differences are measured in units of each model outcome: for the All Zoonoses GAM in Zoonoses and in the Viruses GAMs in Viruses. It is important to note that the significance tests in this type of cross-validation are subject to multiple comparison concerns, just like those in the random cross-validation, so the occasional significant finding should not be over-interpreted. Nevertheless, to be conservative in the performance evaluation of our model we have made no correction for the many comparisons being made at the 5% significance level. 

For the *Strict Zoonoses* model the evidence is more equivocal, with 8 substantial regions that show evidence of bias and 7 substantial regions which show no evidence of bias. This suggests that there might be some unaccounted-for association between zoogeographical region and number of strictly-defined zoonoses present in animals. We took a closer look at each biased region for each model, examining the over- or under-prediction patterns on a species-by-species level; however, no clear interpretable pattern (besides their region) was evident. 

The presence of biased regions across the models suggested the possibility that there is some association between zoogeographical region and our outcomes of interest, but the cross-validation procedure is not the appropriate way to assess this relationship. To that end, we added zoogeographical region as a categorical random effect to the best-fit models for each of our four outcomes.

#Region as Random Effect

Below we add zoographical region as a categorical random effect to each of our best-fit GAMs. The model fit and variable relative deviance explained comparisons for each model follow:

## All Zoonoses GAM
Adding zoogeographical region as a categorical random effect to our best-fit All Zoonoses GAM does not improve the model fit, as seen in the tables below:

```{r non-sig-re}
#All zoonoses
allz_dat <- allz_dat %>%
  mutate(zg_region = as.factor(mam_upgma_))

allz_region_gam <- gam(NSharedWithHoSa ~ s(hAllZACitesLn, bs = "tp", k = 7) + s(hHuntedIUCN, bs = "re") + s(hOrderCETARTIODACTYLA, bs = "re") + 
                       s(hOrderCHIROPTERA, bs = "re") + s(hOrderDIPROTODONTIA, bs = "re") + 
                       s(hOrderPERAMELEMORPHIA, bs = "re") + s(hOrderPERISSODACTYLA, bs = "re") + s(zg_region, bs = "re") +
                       s(hOrderSCANDENTIA, bs = "re") + s(PdHoSa.cbCst, bs = "tp", k = 7) + 
                       s(UrbRurPopRatioLn, bs = "tp", k = 7) + offset(LnTotNumVirus), poisson, allz_dat, select=TRUE)

allz_rep_gam <- gam(NSharedWithHoSa ~ s(hAllZACitesLn, bs = "tp", k = 7) + s(hHuntedIUCN, bs = "re") + s(hOrderCETARTIODACTYLA, bs = "re") + 
                       s(hOrderCHIROPTERA, bs = "re") + s(hOrderDIPROTODONTIA, bs = "re") + 
                       s(hOrderPERAMELEMORPHIA, bs = "re") + s(hOrderPERISSODACTYLA, bs = "re") +
                       s(hOrderSCANDENTIA, bs = "re") + s(PdHoSa.cbCst, bs = "tp", k = 7) + 
                       s(UrbRurPopRatioLn, bs = "tp", k = 7) + offset(LnTotNumVirus), poisson, allz_dat, select=TRUE)

AICs <- c(allz_rep_gam$aic, allz_region_gam$aic)
`Deviance Explained` <- c(1-allz_rep_gam$deviance/allz_rep_gam$null.deviance, 1-allz_region_gam$deviance/allz_region_gam$null.deviance )

mc <- t(tibble(AICs,`Deviance Explained`))
colnames(mc) <- c("Original Model", "Region Model")

kable(mc, caption = "All Zoonoses Model Comparison", digits =4)

allz_relo <- get_relative_contribs(allz_rep_gam) %>% 
  rename(original_rel = rel_deviance_explained)

allz_relg <- get_relative_contribs(allz_region_gam) %>% 
  rename(region_rel = rel_deviance_explained)
  
allz_com <- allz_relo %>%
  full_join(allz_relg, by = "term") 

allz_com %>% rename(`Term` = term, `Original Model Relative Deviance Explained` = original_rel, `Region Model Relative Deviance Explained` = region_rel) %>%
  kable(caption = "All Zoonoses: Original vs. Region Model Relative Deviance Explained", digits = 4)

```
  
  
## All Viruses GAM  
Adding zoogeographical region as a categorical random effect to our best-fit All Viruses GAM improves the model, as seen by the decrease in AIC and the increase in deviance explained.

```{r allv-region}
#All viruses
allv_dat <- allv_dat %>%
  mutate(zg_region = as.factor(mam_upgma_))

allv_rep_gam <-gam(TotVirusPerHost ~  s(hDiseaseZACitesLn, bs = "cs", k = 7) + s(hMassGramsPVR, bs = "cs", k = 7) + s(hOrderCETARTIODACTYLA, bs = "re") + 
    s(hOrderCHIROPTERA, bs = "re") + s(hOrderEULIPOTYPHLA, bs = "re") + 
    s(hOrderPERISSODACTYLA, bs = "re") + s(hOrderPRIMATES, bs = "re") + 
    s(hOrderRODENTIA, bs = "re") + s(LnAreaHost, bs = "cs", k = 7) + 
    s(S20, bs = "cs", k = 7), poisson, allv_dat, select = TRUE)

allv_region_gam <- gam(TotVirusPerHost ~  s(hDiseaseZACitesLn, bs = "cs", k = 7) + s(hMassGramsPVR, bs = "cs", k = 7) + s(hOrderCETARTIODACTYLA, bs = "re") + 
    s(hOrderCHIROPTERA, bs = "re") + s(hOrderEULIPOTYPHLA, bs = "re") + 
    s(hOrderPERISSODACTYLA, bs = "re") + s(hOrderPRIMATES, bs = "re") + 
    s(hOrderRODENTIA, bs = "re") + s(LnAreaHost, bs = "cs", k = 7) + s(zg_region, bs = "re") +
    s(S20, bs = "cs", k = 7), poisson, allv_dat, select = TRUE)

AICs <- c(allv_rep_gam$aic, allv_region_gam$aic)
`Deviance Explained` <- c(1-allv_rep_gam$deviance/allv_rep_gam$null.deviance, 1-allv_region_gam$deviance/allv_region_gam$null.deviance )

mc <- t(tibble(AICs,`Deviance Explained`))
colnames(mc) <- c("Original Model", "Region Model")

kable(mc, caption = "All Viruses Model Comparison", digits =4)

allv_relo <- get_relative_contribs(allv_rep_gam) %>% 
  rename(original_rel = rel_deviance_explained)

allv_relg <- get_relative_contribs(allv_region_gam) %>% 
  rename(region_rel = rel_deviance_explained)
  
allv_com <- allv_relo %>%
  full_join(allv_relg, by = "term") 

allv_com %>% rename(`Term` = term, `Original Model Relative Deviance Explained` = original_rel, `Region Model Relative Deviance Explained` = region_rel) %>%
  kable(caption = "All Viruses: Original vs. Region Model Relative Deviance Explained", digits = 4)


```
  

## Strict Zoonoses GAM
Adding zoogeographical region as a categorical random effect to our best-fit Strict Zoonoses GAM improves the model, as seen by the decrease in AIC and the increase in deviance explained.

```{r strictz-region}
# Strict Zoonoses
strictz_dat <- strictz_dat %>%
  mutate(zg_region = as.factor(mam_upgma_))

sz_rep_gam <- gam(NSharedWithHoSa_strict ~ s(hDiseaseZACitesLn, bs = "tp", k = 7) + 
    s(hMassGramsPVR, bs = "tp", k = 7) + s(hOrderCETARTIODACTYLA, 
    bs = "re") + s(hOrderDIPROTODONTIA, bs = "re") + s(hOrderLAGOMORPHA, 
    bs = "re") + s(hOrderPERISSODACTYLA, bs = "re") + s(hOrderPRIMATES, 
    bs = "re") + s(HumPopDensLnChg, bs = "tp", k = 7) + s(PdHoSa.cbCst, 
    bs = "tp", k = 7) + s(UrbRurPopRatioChg, bs = "tp", k = 7) + 
    offset(LnTotNumVirus), poisson, strictz_dat, select = TRUE)

sz_region_gam <- gam(NSharedWithHoSa_strict ~ s(hDiseaseZACitesLn, bs = "tp", k = 7) + 
    s(hMassGramsPVR, bs = "tp", k = 7) + s(hOrderCETARTIODACTYLA, bs = "re") + 
      s(hOrderDIPROTODONTIA, bs = "re") + s(hOrderLAGOMORPHA, bs = "re") + s(zg_region, bs = "re") +
      s(hOrderPERISSODACTYLA, bs = "re") + s(hOrderPRIMATES, bs = "re") + 
      s(HumPopDensLnChg, bs = "tp", k = 7) + s(PdHoSa.cbCst, bs = "tp", k = 7) + 
      s(UrbRurPopRatioChg, bs = "tp", k = 7) + offset(LnTotNumVirus), poisson, strictz_dat, select = TRUE)

AICs <- c(sz_rep_gam$aic, sz_region_gam$aic)
`Deviance Explained` <- c(1-sz_rep_gam$deviance/sz_rep_gam$null.deviance, 1-sz_region_gam$deviance/sz_region_gam$null.deviance )

mc <- t(tibble(AICs,`Deviance Explained`))
colnames(mc) <- c("Original Model", "Region Model")

kable(mc, caption = "Strict Zoonoses Model Comparison", digits =4)

sz_relo <- get_relative_contribs(sz_rep_gam) %>% 
  rename(original_rel = rel_deviance_explained)

sz_relg <- get_relative_contribs(sz_region_gam) %>% 
  rename(region_rel = rel_deviance_explained)
  
sz_com <- sz_relo %>%
  full_join(sz_relg, by = "term") 

sz_com %>% rename(`Term` = term, `Original Model Relative Deviance Explained` = original_rel, `Region Model Relative Deviance Explained` = region_rel) %>%
  kable(caption = "Strict Zoonoses: Original vs. Region Model Relative Deviance Explained", digits = 4)


```
  

##Strict Viruses GAM
Adding zoogeographical region as a categorical random effect to our best-fit Strict Viruses GAM improves the model, as seen by the decrease in AIC and the increase in deviance explained.

```{r strictv-region}
strictv_dat <- strictv_dat %>%
  mutate(zg_region = as.factor(mam_upgma_))

strictv_rep_gam <- gam(TotVirusPerHost_strict ~ s(hDiseaseZACitesLn, bs = "cs", k = 7) + 
    s(hMassGramsPVR, bs = "cs", k = 7) + s(hOrderCHIROPTERA, bs = "re") + 
    s(hOrderCINGULATA, bs = "re") + s(hOrderEULIPOTYPHLA, bs = "re") + 
    s(hOrderPERAMELEMORPHIA, bs = "re") + s(hOrderPRIMATES, bs = "re") + 
    s(hOrderRODENTIA, bs = "re") + s(hOrderSCANDENTIA, bs = "re") + 
    s(LnAreaHost, bs = "cs", k = 7) + s(S20, bs = "cs", k = 7), poisson, strictv_dat, select=TRUE)

strictv_region_gam <- gam(TotVirusPerHost_strict ~ s(hDiseaseZACitesLn, bs = "cs", k = 7) + 
    s(hMassGramsPVR, bs = "cs", k = 7) + s(hOrderCHIROPTERA, bs = "re") + 
    s(hOrderCINGULATA, bs = "re") + s(hOrderEULIPOTYPHLA, bs = "re") + 
    s(hOrderPERAMELEMORPHIA, bs = "re") + s(hOrderPRIMATES, bs = "re") + s(zg_region, bs = "re") +
    s(hOrderRODENTIA, bs = "re") + s(hOrderSCANDENTIA, bs = "re") + 
    s(LnAreaHost, bs = "cs", k = 7) + s(S20, bs = "cs", k = 7), poisson, strictv_dat, select=TRUE)


AICs <- c(strictv_rep_gam$aic, strictv_region_gam$aic)
`Deviance Explained` <- c(1-strictv_rep_gam$deviance/strictv_rep_gam$null.deviance, 1-strictv_region_gam$deviance/strictv_region_gam$null.deviance )

mc <- t(tibble(AICs,`Deviance Explained`))
colnames(mc) <- c("Original Model", "Region Model")

kable(mc, caption = "Strict Viruses Model Comparison", digits =4)

strictv_relo <- get_relative_contribs(strictv_rep_gam) %>% 
  rename(original_rel = rel_deviance_explained)

strictv_relg <- get_relative_contribs(strictv_region_gam) %>% 
  rename(region_rel = rel_deviance_explained)
  
strictv_com <- strictv_relo %>%
  full_join(strictv_relg, by = "term") 

strictv_com %>% rename(`Term` = term, `Original Model Relative Deviance Explained` = original_rel, `Region Model Relative Deviance Explained` = region_rel) %>%
  kable(caption = "Strict Viruses: Original vs. Region Model Relative Deviance Explained", digits = 4)

```
  

## Random Effect Model Interpretation  
For three of our best-fit GAMS (*All Viruses*, *Strict Zoonoses*, and *Strict Viruses*) the addition of zoogeographical region as a categorical random effect decreased the model AIC and increased the deviance explained by 3-5%. These results support the reviewer's suggestion that there might be a stronger relationship between geography and our outcomes of interest than was previously accounted for in these models. The *All Zoonoses* model, which is used to create the series of maps in the main manuscript, does not improve with the inclusion of zoogeographical region.

Taking a closer look at the change in relative deviance explained when we add zoogeographical region, we see most of the variables with substantial decreases in deviance explained when region is included are closely connected to geography: LnAreaHost (host area), S20 (species range 20% overlap), HumPopDensLnChg (human population density change). This is not surprising, since the inclusion of another (likely non-independent) geographic variable might be expected to siphon away the relative effect of these variables, although over-interpreting the specific changes in deviance explained by competing terms is inappropriate. We might have more deeply investigated the details of this zoogeographical variable by separating out the effect of each region during our model selection process (as we did with taxonomic Order); however, we felt that the improved predictive power of a model using region-specific terms was offset by the decreased interpretability of these terms -- especially when compared to the pre-existing geographical variables, such as host area or overlapping species range. The association between variables like host range or human population density change and our outcomes of interest are interpretable in relevant, biologically plausible ways; in pursuing our goal to both predict and understand, we choose to trade off some gains in prediction for interpretability in the case of zoogeographical region. 

# Conclusion
The zoogeographical cross-validation procedure and the subsequent inclusion of region into our GAMs reveals that for the *All Viruses*, *Strict Zoonoses*, and *Strict Viruses* models, the addition of a region term would improve deviance explained by 3-5%. However, this modest increase in predictive power does come with some cost in interpretation, so we decided not to include zoogeographical region in our final models. 

It is evident that at the core of the reviewer's astute questions regarding these models is an important concern about the translation of GAM predictions, whose parameter estimates' uncertainty and deviance explained can be clearly stated or visualized, into layered raster maps, whose uncertainty is more difficult to convey to readers. This point is well-taken, and we do not wish to invite over-interpretation of the regions identified by our maps: they are a result of imperfect models that only explain a portion of deviance in the data. In order to more explicitly express this fact, we have included additional maps that illustate this uncertainty. 
